{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "from pprint import pprint\n",
    "import networkx as nx\n",
    "import igraph as ig\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from collections import deque\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misc testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roc_bike_growth.loader import carall_from_polygon, bike_infra_from_polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hoang\\miniconda3\\envs\\ox\\lib\\site-packages\\osmnx\\geocoder.py:110: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  gdf = gdf.append(_geocode_query_to_gdf(q, wr, by_osmid))\n"
     ]
    }
   ],
   "source": [
    "rochester = ox.geocode_to_gdf('rochester, ny').geometry[0]\n",
    "# carall = carall_from_polygon(rochester, add_pois=True)\n",
    "bike_infra = bike_infra_from_polygon(rochester)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = bike_infra.edges()\n",
    "nodes = list(bike_infra.nodes())\n",
    "adjacency_mat = nx.adjacency_matrix(bike_infra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adjacency_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_largest = []\n",
    "G_new = bike_infra.to_undirected(as_view=False)\n",
    "print(len(list(G_new.edges())))\n",
    "edges = list(G_new.edges())\n",
    "\n",
    "for edge in tqdm(edges):\n",
    "    G_new.remove_edge(edge[0], edge[1])\n",
    "    largest_component = max(nx.connected_components(G_new), key=len)\n",
    "    running_largest.append(len(largest_component))\n",
    "    \n",
    "print(running_largest)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics self implemented / package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def graph_resilience(G, variant = 'density'):\n",
    "    assert variant in ['density', 'largest_component']\n",
    "    if variant == 'density':\n",
    "        return round(nx.density(G)*100, 2)\n",
    "    elif variant == 'largest_component':\n",
    "        G_new = G.to_undirected(as_view=False)\n",
    "        return len(max(nx.connected_components(G_new), key=len))\n",
    "\n",
    "def graph_cohesion(G, coverage):\n",
    "    assert isinstance(coverage, float) \n",
    "    G_new = G.to_undirected(as_view=False)\n",
    "    n_components = nx.number_connected_components(G_new)\n",
    "    return round(coverage / (n_components**1.2 + 0.00001), 2)\n",
    "\n",
    "def graph_global_efficiency(G):\n",
    "    G_new = G.to_undirected(as_view=False)\n",
    "    return nx.algorithms.efficiency_measures.global_efficiency(G_new)\n",
    "\n",
    "def graph_local_efficiency(G):\n",
    "    G_new = G.to_undirected(as_view=False)\n",
    "    return nx.algorithms.efficiency_measures.local_efficiency(G_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metric paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from haversine import haversine_vector\n",
    "import itertools\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dist_vector(v1_list, v2_list):\n",
    "    dist_list = haversine_vector(v1_list, v2_list, unit=\"m\") # [(lat,lon)], [(lat,lon)]\n",
    "    return dist_list\n",
    "\n",
    "def paper_global_efficiency(G, pairs_thresh=500):\n",
    "    # Input is a igraph Graph\n",
    "    try:\n",
    "        G = ig.Graph.from_networkx(nx.Graph(G))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if G.vcount() > pairs_thresh:\n",
    "        nodeindices = random.sample(list(G.vs.indices), pairs_thresh)\n",
    "    else:\n",
    "        nodeindices = list(G.vs.indices)\n",
    "    \n",
    "    d_ij = G.shortest_paths(source = nodeindices, target = nodeindices)\n",
    "    d_ij = [item for sublist in d_ij for item in sublist] # flatten\n",
    "    EG  = sum([1/d for d in d_ij if d != 0])\n",
    "    pairs = list(itertools.permutations(nodeindices, 2))\n",
    "    l_ij = dist_vector([(G.vs[p[0]][\"y\"], G.vs[p[0]][\"x\"]) for p in pairs],\n",
    "                            [(G.vs[p[1]][\"y\"], G.vs[p[1]][\"x\"]) for p in pairs]) # must be in format lat,lon = y,x\n",
    "    EG_id = sum([1/l for l in l_ij if l != 0])\n",
    "    \n",
    "    return round(EG / EG_id, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_local_efficiency(G, numnodepairs=500):\n",
    "    # Input is a igraph Graph\n",
    "    try:\n",
    "        G = ig.Graph.from_networkx(nx.Graph(G))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if G.vcount() > numnodepairs:\n",
    "        nodeindices = random.sample(list(G.vs.indices), numnodepairs)\n",
    "    else:\n",
    "        nodeindices = list(G.vs.indices)\n",
    "    EGi = []\n",
    "    for i in nodeindices:\n",
    "        if len(G.neighbors(i)) > 1: # If we have a nontrivial neighborhood\n",
    "            G_induced = G.induced_subgraph(G.neighbors(i))\n",
    "            EGi.append(paper_global_efficiency(G_induced, numnodepairs))\n",
    "    EGi = sum(EGi) / len(EGi)\n",
    "    \n",
    "    return round(EGi, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj\n",
    "from shapely import ops\n",
    "from shapely.geometry import Polygon, LineString\n",
    "import copy\n",
    "\n",
    "def paper_coverage(G):\n",
    "    G = ig.Graph.from_networkx(nx.Graph(G))\n",
    "    G_added = copy.deepcopy(G)\n",
    "    \n",
    "    # https://gis.stackexchange.com/questions/121256/creating-a-circle-with-radius-in-metres\n",
    "    longitudes = [v[\"x\"] for v in G.vs]\n",
    "    loncenter = sum(longitudes) / (len(longitudes) + 0.0001)\n",
    "    latitudes = [v[\"y\"] for v in G.vs]\n",
    "    latcenter = sum(latitudes) / (len(latitudes) + 0.0001)\n",
    "    local_azimuthal_projection = \"+proj=aeqd +R=6371000 +units=m +lat_0={} +lon_0={}\".format(latcenter, loncenter)\n",
    "    \n",
    "    # Use transformer: https://gis.stackexchange.com/questions/127427/transforming-shapely-polygon-and-multipolygon-objects\n",
    "    wgs84_to_aeqd = pyproj.Transformer.from_proj(\n",
    "        pyproj.Proj(\"+proj=longlat +datum=WGS84 +no_defs\"),\n",
    "        pyproj.Proj(local_azimuthal_projection))\n",
    "    aeqd_to_wgs84 = pyproj.Transformer.from_proj(\n",
    "        pyproj.Proj(local_azimuthal_projection),\n",
    "        pyproj.Proj(\"+proj=longlat +datum=WGS84 +no_defs\"))\n",
    "    edgetuples = [((e.source_vertex[\"x\"], e.source_vertex[\"y\"]), (e.target_vertex[\"x\"], e.target_vertex[\"y\"])) for e in G_added.es]\n",
    "    \n",
    "    # # Shapely buffer seems slow for complex objects: https://stackoverflow.com/questions/57753813/speed-up-shapely-buffer\n",
    "    # # Therefore we buffer piecewise.\n",
    "    cov_added = Polygon()\n",
    "    for c, t in enumerate(edgetuples):\n",
    "        buf = ops.transform(aeqd_to_wgs84.transform, ops.transform(wgs84_to_aeqd.transform, LineString(t)).buffer(500))\n",
    "        cov_added = ops.unary_union([cov_added, Polygon(buf)])\n",
    "\n",
    "    cov_transformed = ops.transform(wgs84_to_aeqd.transform, cov_added)\n",
    "    covered_area = cov_transformed.area / 1000000 # turn from m2 to km2\n",
    "\n",
    "    return covered_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import igraph as ig\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from roc_bike_growth.loader import POI_graph_from_polygon, bike_infra_from_polygon, carall_from_polygon\n",
    "from roc_bike_growth.paper_gt import gt_with_existing_full\n",
    "\n",
    "class BikeGraph:\n",
    "    def __init__(self, prune_factor=0.1, route_factor=1):\n",
    "        self.prune_factor = prune_factor\n",
    "        self.route_factor = route_factor\n",
    "        car_infra, bike_infra = self.get_data()\n",
    "        self.bike_graph = self.merge_and_gt(car_infra, bike_infra)\n",
    "        \n",
    "    def get_data(self):\n",
    "        rochester = ox.geocode_to_gdf('rochester, ny').geometry[0]\n",
    "        bike_infra = bike_infra_from_polygon(rochester)\n",
    "        car_infra = carall_from_polygon(rochester, add_pois=True)\n",
    "        \n",
    "        return car_infra, bike_infra\n",
    "    \n",
    "    def merge_and_gt(self, car_infra, bike_infra):\n",
    "        return gt_with_existing_full(car_infra, bike_infra, self.route_factor, self.prune_factor)\n",
    "    \n",
    "    def plot_graph(self, add_pois=False):\n",
    "        fig, ax = ox.plot.plot_graph(self.bike_graph)\n",
    "        # Plot POIs on graph\n",
    "        if add_pois:\n",
    "            x, y = [], []\n",
    "            pois = nx.get_node_attributes(self.bike_graph, 'poi').keys()\n",
    "            for node in pois:\n",
    "                d = self.bike_graph.nodes()[node]\n",
    "                x.append(d['x'])\n",
    "                y.append(d['y'])\n",
    "            ax.scatter(x,y)\n",
    "            fig\n",
    "    \n",
    "    def display_final_metrics(self):\n",
    "        res_density = graph_resilience(self.bike_graph, 'density')\n",
    "        res_component = graph_resilience(self.bike_graph, 'largest_component')\n",
    "        coverage = paper_coverage(self.bike_graph)\n",
    "        cohesion = graph_cohesion(self.bike_graph, coverage)\n",
    "        global_eff = paper_global_efficiency(self.bike_graph)\n",
    "        local_eff = paper_local_efficiency(self.bike_graph)\n",
    "                \n",
    "        plot_data = pd.DataFrame(dict(\n",
    "           theta = ['resilience (density)','resilience (largest_component)','coverage','cohesion', 'global efficiency', 'local efficiency'],\n",
    "           r = [res_density, res_component, coverage, cohesion, global_eff, local_eff]\n",
    "        ))\n",
    "        fig = px.line_polar(plot_data, r='r', theta='theta', line_close=True)\n",
    "        fig.show()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hoang\\miniconda3\\envs\\ox\\lib\\site-packages\\osmnx\\geocoder.py:110: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  gdf = gdf.append(_geocode_query_to_gdf(q, wr, by_osmid))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception at Port of Rochester, Lake Ave . This point will be dropped:\n",
      " Nominatim could not geocode query \"Port of Rochester, Lake Ave  rochester ny\"\n",
      "Exception at 810-846 N GOODMAN ST. This point will be dropped:\n",
      " Nominatim could not geocode query \"810-846 N GOODMAN ST rochester ny\"\n",
      "Exception at 650-672 E Main St. This point will be dropped:\n",
      " Nominatim could not geocode query \"650-672 E Main St rochester ny\"\n",
      "Exception at 497-499 S. CLINTON. This point will be dropped:\n",
      " Nominatim could not geocode query \"497-499 S. CLINTON rochester ny\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\work\\grad\\y1s2\\capstone\\project\\roc-bike-growth\\roc_bike_growth\\paper_gt.py:23: RuntimeWarning: Couldn't reach some vertices at src/paths/unweighted.c:368\n",
      "  poi_nodes.append(G.get_shortest_paths(v, pois_indices[c:], output=\"vpath\"))\n",
      "d:\\work\\grad\\y1s2\\capstone\\project\\roc-bike-growth\\roc_bike_growth\\paper_gt.py:24: RuntimeWarning: Couldn't reach some vertices at src/paths/unweighted.c:368\n",
      "  poi_edges.append(G.get_shortest_paths(v, pois_indices[c:], output=\"epath\"))\n"
     ]
    }
   ],
   "source": [
    "roc_bike_graph = BikeGraph(prune_factor=1, route_factor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_bike_graph.display_final_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_bike_graph.plot_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11 1795 108.02641503884439 1.69 87.86 2.59\n"
     ]
    }
   ],
   "source": [
    "res_density = graph_resilience(roc_bike_graph.bike_graph, 'density')\n",
    "res_component = graph_resilience(roc_bike_graph.bike_graph, 'largest_component')\n",
    "coverage = paper_coverage(roc_bike_graph.bike_graph)\n",
    "cohesion = graph_cohesion(roc_bike_graph.bike_graph, coverage)\n",
    "global_eff = paper_global_efficiency(roc_bike_graph.bike_graph)\n",
    "local_eff = paper_local_efficiency(roc_bike_graph.bike_graph)\n",
    "\n",
    "print(res_density, res_component, coverage, cohesion, global_eff, local_eff)\n",
    "\n",
    "plot_data = pd.DataFrame(dict(\n",
    "    theta = ['resilience (density)','resilience (largest_component)','coverage','cohesion', 'global efficiency', 'local efficiency'],\n",
    "    r = [res_density, res_component / 286, coverage/100, cohesion, global_eff/100, local_eff/100]\n",
    "))\n",
    "fig = px.line_polar(plot_data, r='r', theta='theta', line_close=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "prune_fs = np.arange(0.1, 1, 0.1)\n",
    "route_fs = np.arange(0.1, 1, 0.1)\n",
    "for prune_f in tqdm(prune_fs):\n",
    "    for route_f in route_fs:\n",
    "        bike_map = BikeGraph(prune_factor=prune_f, route_factor=route_f)\n",
    "        \n",
    "        res_density = graph_resilience(bike_map.bike_graph, 'density')\n",
    "        res_component = graph_resilience(bike_map.bike_graph, 'largest_component')\n",
    "        coverage = paper_coverage(bike_map.bike_graph)\n",
    "        cohesion = graph_cohesion(bike_map.bike_graph, coverage)\n",
    "        global_eff = paper_global_efficiency(bike_map.bike_graph)\n",
    "        local_eff = paper_local_efficiency(bike_map.bike_graph)\n",
    "        \n",
    "        data.append({\n",
    "            'prune_f': prune_f,\n",
    "            'route_f': route_f,\n",
    "            'res_density': res_density,\n",
    "            'res_component': res_component,\n",
    "            'coverage': coverage,\n",
    "            'cohesion': cohesion,\n",
    "            'global_eff': global_eff/100,\n",
    "            'local_eff': local_eff/100\n",
    "        })\n",
    "        \n",
    "with open('output\\\\results.json', 'w') as f:\n",
    "    json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2aa4ef88a60d511689f4f8de835e153dc4058a6f3d8ffa213cd6f60262bac7e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ox')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
