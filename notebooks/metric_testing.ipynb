{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "from pprint import pprint\n",
    "import networkx as nx\n",
    "import igraph as ig\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from collections import deque\n",
    "# os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misc testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roc_bike_growth.loader import carall_from_polygon, bike_infra_from_polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rochester = ox.geocode_to_gdf('rochester, ny').geometry[0]\n",
    "# carall = carall_from_polygon(rochester, add_pois=True)\n",
    "bike_infra = bike_infra_from_polygon(rochester)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = bike_infra.edges()\n",
    "nodes = list(bike_infra.nodes())\n",
    "adjacency_mat = nx.adjacency_matrix(bike_infra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adjacency_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_largest = []\n",
    "G_new = bike_infra.to_undirected(as_view=False)\n",
    "print(len(list(G_new.edges())))\n",
    "edges = list(G_new.edges())\n",
    "\n",
    "for edge in tqdm(edges):\n",
    "    G_new.remove_edge(edge[0], edge[1])\n",
    "    largest_component = max(nx.connected_components(G_new), key=len)\n",
    "    running_largest.append(len(largest_component))\n",
    "    \n",
    "print(running_largest)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics self implemented / package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def graph_resilience(G, variant = 'density'):\n",
    "    assert variant in ['density', 'largest_component']\n",
    "    if variant == 'density':\n",
    "        return round(nx.density(G)*100, 2)\n",
    "    elif variant == 'largest_component':\n",
    "        G_new = G.to_undirected(as_view=False)\n",
    "        return len(max(nx.connected_components(G_new), key=len))\n",
    "\n",
    "def graph_cohesion(G, coverage):\n",
    "    assert isinstance(coverage, float) \n",
    "    G_new = G.to_undirected(as_view=False)\n",
    "    n_components = nx.number_connected_components(G_new)\n",
    "    return round(coverage / (n_components**1.2 + 0.00001), 2)\n",
    "\n",
    "def graph_global_efficiency(G):\n",
    "    G_new = G.to_undirected(as_view=False)\n",
    "    return nx.algorithms.efficiency_measures.global_efficiency(G_new)\n",
    "\n",
    "def graph_local_efficiency(G):\n",
    "    G_new = G.to_undirected(as_view=False)\n",
    "    return nx.algorithms.efficiency_measures.local_efficiency(G_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metric paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from haversine import haversine_vector, haversine\n",
    "import itertools\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dist_vector(v1_list, v2_list):\n",
    "    dist_list = haversine_vector(v1_list, v2_list, unit=\"m\") # [(lat,lon)], [(lat,lon)]\n",
    "    return dist_list\n",
    "\n",
    "def paper_global_efficiency(G, pairs_thresh=500):\n",
    "    # Input is a igraph Graph\n",
    "    try:\n",
    "        G = ig.Graph.from_networkx(nx.Graph(G))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if G.vcount() > pairs_thresh:\n",
    "        nodeindices = random.sample(list(G.vs.indices), pairs_thresh)\n",
    "    else:\n",
    "        nodeindices = list(G.vs.indices)\n",
    "    \n",
    "    d_ij = G.shortest_paths(source = nodeindices, target = nodeindices)\n",
    "    d_ij = [item for sublist in d_ij for item in sublist] # flatten\n",
    "    EG  = sum([1/d for d in d_ij if d != 0])\n",
    "    pairs = list(itertools.permutations(nodeindices, 2))\n",
    "    l_ij = dist_vector([(G.vs[p[0]][\"y\"], G.vs[p[0]][\"x\"]) for p in pairs],\n",
    "                            [(G.vs[p[1]][\"y\"], G.vs[p[1]][\"x\"]) for p in pairs]) # must be in format lat,lon = y,x\n",
    "    EG_id = sum([1/l for l in l_ij if l != 0])\n",
    "    \n",
    "    return round(EG / EG_id, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_local_efficiency(G, numnodepairs=500):\n",
    "    # Input is a igraph Graph\n",
    "    try:\n",
    "        G = ig.Graph.from_networkx(nx.Graph(G))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if G.vcount() > numnodepairs:\n",
    "        nodeindices = random.sample(list(G.vs.indices), numnodepairs)\n",
    "    else:\n",
    "        nodeindices = list(G.vs.indices)\n",
    "    EGi = []\n",
    "    for i in nodeindices:\n",
    "        if len(G.neighbors(i)) > 1: # If we have a nontrivial neighborhood\n",
    "            G_induced = G.induced_subgraph(G.neighbors(i))\n",
    "            EGi.append(paper_global_efficiency(G_induced, numnodepairs))\n",
    "    EGi = sum(EGi) / len(EGi)\n",
    "    \n",
    "    return round(EGi, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj\n",
    "from shapely import ops\n",
    "from shapely.geometry import Polygon, LineString\n",
    "import copy\n",
    "\n",
    "def paper_coverage(G, buffer=500):\n",
    "    G = ig.Graph.from_networkx(nx.Graph(G))\n",
    "    G_added = copy.deepcopy(G)\n",
    "    \n",
    "    # https://gis.stackexchange.com/questions/121256/creating-a-circle-with-radius-in-metres\n",
    "    longitudes = [v[\"x\"] for v in G.vs]\n",
    "    loncenter = sum(longitudes) / (len(longitudes) + 0.0001)\n",
    "    latitudes = [v[\"y\"] for v in G.vs]\n",
    "    latcenter = sum(latitudes) / (len(latitudes) + 0.0001)\n",
    "    local_azimuthal_projection = \"+proj=aeqd +R=6371000 +units=m +lat_0={} +lon_0={}\".format(latcenter, loncenter)\n",
    "    \n",
    "    # Use transformer: https://gis.stackexchange.com/questions/127427/transforming-shapely-polygon-and-multipolygon-objects\n",
    "    wgs84_to_aeqd = pyproj.Transformer.from_proj(\n",
    "        pyproj.Proj(\"+proj=longlat +datum=WGS84 +no_defs\"),\n",
    "        pyproj.Proj(local_azimuthal_projection))\n",
    "    aeqd_to_wgs84 = pyproj.Transformer.from_proj(\n",
    "        pyproj.Proj(local_azimuthal_projection),\n",
    "        pyproj.Proj(\"+proj=longlat +datum=WGS84 +no_defs\"))\n",
    "    edgetuples = [((e.source_vertex[\"x\"], e.source_vertex[\"y\"]), (e.target_vertex[\"x\"], e.target_vertex[\"y\"])) for e in G_added.es]\n",
    "    \n",
    "    # # Shapely buffer seems slow for complex objects: https://stackoverflow.com/questions/57753813/speed-up-shapely-buffer\n",
    "    # # Therefore we buffer piecewise.\n",
    "    cov_added = Polygon()\n",
    "    for c, t in enumerate(edgetuples):\n",
    "        buf = ops.transform(aeqd_to_wgs84.transform, ops.transform(wgs84_to_aeqd.transform, LineString(t)).buffer(buffer))\n",
    "        cov_added = ops.unary_union([cov_added, Polygon(buf)])\n",
    "\n",
    "    cov_transformed = ops.transform(wgs84_to_aeqd.transform, cov_added)\n",
    "    covered_area = cov_transformed.area / 1000000 # turn from m2 to km2\n",
    "\n",
    "    return covered_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geographic_length(G):    \n",
    "    try:\n",
    "        G = ig.Graph.from_networkx(nx.Graph(G))\n",
    "    except:\n",
    "        pass\n",
    "    length = 0\n",
    "    for edge in G.es:\n",
    "        point_0 = (G.vs[edge.source]['y'], G.vs[edge.source]['x'])\n",
    "        point_1 = (G.vs[edge.target]['y'], G.vs[edge.target]['x'])\n",
    "        \n",
    "        length += haversine(point_0, point_1, 'km')\n",
    "    \n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import igraph as ig\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from roc_bike_growth.loader import POI_graph_from_polygon, bike_infra_from_polygon, carall_from_polygon\n",
    "from roc_bike_growth.paper_gt import gt_with_existing_full\n",
    "\n",
    "class BikeGraph:\n",
    "    def __init__(self, prune_factor=0.1, route_factor=1):\n",
    "        self.prune_factor = prune_factor\n",
    "        self.route_factor = route_factor\n",
    "        car_infra, bike_infra = self.get_data()\n",
    "        self.bike_graph = self.merge_and_gt(car_infra, bike_infra)\n",
    "        \n",
    "    def get_data(self):\n",
    "        rochester = ox.geocode_to_gdf('rochester, ny').geometry[0]\n",
    "        bike_infra = bike_infra_from_polygon(rochester)\n",
    "        car_infra = carall_from_polygon(rochester, add_pois=True)\n",
    "        \n",
    "        return car_infra, bike_infra\n",
    "    \n",
    "    def merge_and_gt(self, car_infra, bike_infra):\n",
    "        return gt_with_existing_full(car_infra, bike_infra, self.route_factor, self.prune_factor)\n",
    "    \n",
    "    def plot_graph(self, add_pois=False):\n",
    "        fig, ax = ox.plot.plot_graph(self.bike_graph)\n",
    "        # Plot POIs on graph\n",
    "        if add_pois:\n",
    "            x, y = [], []\n",
    "            pois = nx.get_node_attributes(self.bike_graph, 'poi').keys()\n",
    "            for node in pois:\n",
    "                d = self.bike_graph.nodes()[node]\n",
    "                x.append(d['x'])\n",
    "                y.append(d['y'])\n",
    "            ax.scatter(x,y)\n",
    "            fig\n",
    "    \n",
    "    def display_final_metrics(self):\n",
    "        res_density = graph_resilience(self.bike_graph, 'density')\n",
    "        res_component = graph_resilience(self.bike_graph, 'largest_component')\n",
    "        coverage = paper_coverage(self.bike_graph)\n",
    "        cohesion = graph_cohesion(self.bike_graph, coverage)\n",
    "        global_eff = paper_global_efficiency(self.bike_graph)\n",
    "        local_eff = paper_local_efficiency(self.bike_graph)\n",
    "                \n",
    "        plot_data = pd.DataFrame(dict(\n",
    "           theta = ['resilience (density)','resilience (largest_component)','coverage','cohesion', 'global efficiency', 'local efficiency'],\n",
    "           r = [res_density, res_component, coverage, cohesion, global_eff, local_eff]\n",
    "        ))\n",
    "        fig = px.line_polar(plot_data, r='r', theta='theta', line_close=True)\n",
    "        fig.show()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "roc_bike_graph = BikeGraph(prune_factor=1, route_factor=1)\n",
    "# roc_bike_graph.display_final_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(v1, v2):\n",
    "    dist = haversine((v1['y'],v1['x']),(v2['y'],v2['x']), unit=\"m\") # x is lon, y is lat\n",
    "    return dist\n",
    "\n",
    "def calculate_directness_linkwise(G):\n",
    "    \"\"\"Calculate directness on G over all connected node pairs in indices. This is maybe the common calculation method: It takes the average of linkwise euclidian distances divided by network distances.\n",
    "        If G has multiple components, node pairs in different components are discarded.\n",
    "    \"\"\"\n",
    "    G = G.to_undirected(as_view=False)\n",
    "    try:\n",
    "        G = ig.Graph.from_networkx(nx.Graph(G))\n",
    "    except:\n",
    "        pass\n",
    "    nodes = list(G.vs)\n",
    "    out = []\n",
    "    error = 0\n",
    "    for i_node, node in enumerate(nodes):\n",
    "        poi_edges = G.get_shortest_paths(node, nodes[i_node:],output=\"epath\")\n",
    "        for i_neighbor, path_e in enumerate(poi_edges[1:]):\n",
    "            if path_e:\n",
    "                distance_direct = dist(node, nodes[i_node+i_neighbor])\n",
    "                distance_network = max(distance_direct, sum(filter(None, [G.es[e]['weight'] for e in path_e])))\n",
    "                out.append(distance_direct / (distance_network+0.000001))\n",
    "    \n",
    "    return sum(out) / len(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_map = BikeGraph(prune_factor=0.1, route_factor=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directness = calculate_directness_linkwise(bike_map.bike_graph)\n",
    "print(directness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_bike_graph.plot_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_density = graph_resilience(roc_bike_graph.bike_graph, 'density')\n",
    "res_component = graph_resilience(roc_bike_graph.bike_graph, 'largest_component')\n",
    "directness = calculate_directness_linkwise(roc_bike_graph.bike_graph)\n",
    "coverage = paper_coverage(roc_bike_graph.bike_graph)\n",
    "path_length = geographic_length(roc_bike_graph.bike_graph)\n",
    "cohesion = graph_cohesion(roc_bike_graph.bike_graph, coverage)\n",
    "global_eff = paper_global_efficiency(roc_bike_graph.bike_graph)\n",
    "local_eff = paper_local_efficiency(roc_bike_graph.bike_graph)\n",
    "\n",
    "print(res_density, res_component, directness, coverage, path_length, cohesion, global_eff, local_eff)\n",
    "\n",
    "# plot_data = pd.DataFrame(dict(\n",
    "#     theta = ['resilience (density)','resilience (largest_component)','coverage','cohesion', 'global efficiency', 'local efficiency'],\n",
    "#     r = [res_density, res_component / 286, coverage/100, cohesion, global_eff/100, local_eff/100]\n",
    "# ))\n",
    "# fig = px.line_polar(plot_data, r='r', theta='theta', line_close=True)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "prune_fs = np.arange(0.05, 1.02, 0.05)\n",
    "route_fs = [1]\n",
    "print(prune_fs)\n",
    "print(route_fs)\n",
    "for prune_f in tqdm(prune_fs):\n",
    "    for route_f in route_fs:\n",
    "        # try:\n",
    "        bike_map = BikeGraph(prune_factor=prune_f, route_factor=route_f)\n",
    "    \n",
    "        res_density = graph_resilience(bike_map.bike_graph, 'density')\n",
    "        res_component = graph_resilience(bike_map.bike_graph, 'largest_component')\n",
    "        directness = calculate_directness_linkwise(bike_map.bike_graph)\n",
    "        coverage = paper_coverage(bike_map.bike_graph)\n",
    "        path_length = geographic_length(bike_map.bike_graph)\n",
    "        cohesion = graph_cohesion(bike_map.bike_graph, coverage)\n",
    "        global_eff = paper_global_efficiency(bike_map.bike_graph)\n",
    "        local_eff = paper_local_efficiency(bike_map.bike_graph)\n",
    "        # except:\n",
    "        #     # res_density = None\n",
    "        #     # res_component = None\n",
    "        #     directness = None\n",
    "        #     # coverage = None\n",
    "        #     path_length = None\n",
    "        #     # cohesion = None\n",
    "        #     # global_eff = None\n",
    "        #     # local_eff = None\n",
    "        \n",
    "        data.append({\n",
    "            'prune_f': prune_f,\n",
    "            'route_f': route_f,\n",
    "            'res_density': res_density,\n",
    "            'res_component': res_component,\n",
    "            'directness': directness,\n",
    "            'coverage': coverage,\n",
    "            'length': path_length,\n",
    "            'cohesion': cohesion,\n",
    "            'global_eff': global_eff/100,\n",
    "            'local_eff': local_eff/100\n",
    "        })\n",
    "        \n",
    "with open('output\\\\results_directness_length.json', 'w') as f:\n",
    "    json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output\\\\original_all_metrics.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "res_density = -1\n",
    "res_component = -1\n",
    "coverage = -1\n",
    "length = -1\n",
    "diectness = -1\n",
    "cohesion = -1\n",
    "global_eff = -1\n",
    "local_eff = -1\n",
    "\n",
    "for setting in data:\n",
    "    res_density = max(res_density, setting['res_density'])\n",
    "    res_component = max(res_component, setting['res_component'])\n",
    "    coverage = max(coverage, setting['coverage'])\n",
    "    length = max(length, setting['length'])\n",
    "    cohesion = max(cohesion, setting['cohesion'])\n",
    "    global_eff = max(global_eff, setting['global_eff'])\n",
    "    local_eff = max(local_eff, setting['local_eff'])\n",
    "    directness = max(directness, setting['directness'])\n",
    "    \n",
    "print(res_density, res_component, coverage, cohesion, global_eff, local_eff, length, directness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "out = []\n",
    "\n",
    "with open('output\\\\results_new.json', 'r') as f:\n",
    "    m_data = json.load(f)\n",
    "    \n",
    "with open('output\\\\results_directness_length.json', 'r') as f:\n",
    "    dl_data = json.load(f)\n",
    "\n",
    "additional_metrics = {}\n",
    "for sample in dl_data:\n",
    "    key = str(sample['prune_f']) + '_' + str(sample['route_f'])\n",
    "    value = {'directness': sample['directness'],\n",
    "             'length': sample['length']}\n",
    "    additional_metrics[key] = value\n",
    "    \n",
    "for sample in m_data:\n",
    "    if sample['route_f'] == 1:\n",
    "        route_f = '1'\n",
    "        key = str(sample['prune_f']) + '_' + route_f\n",
    "        directness = additional_metrics[key]['directness']\n",
    "        length = additional_metrics[key]['length']\n",
    "    else:\n",
    "        directness = -1\n",
    "        length = -1\n",
    "    \n",
    "    sample['directness'] = directness\n",
    "    sample['length'] = length\n",
    "    \n",
    "with open('output\\\\original_all_metrics.json', 'w') as f:\n",
    "    json.dump(m_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import plotly.express as px\n",
    "with open('output\\original_all_metrics.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for scenario in data:\n",
    "    route_f = scenario['route_f']\n",
    "    prune_f = scenario['prune_f']\n",
    "    \n",
    "    res_density = scenario['res_density']\n",
    "    res_component = scenario['res_component']\n",
    "    coverage = scenario['coverage']\n",
    "    directness = scenario['directness']\n",
    "    length = scenario['length']\n",
    "    cohesion = scenario['cohesion']\n",
    "    global_eff = scenario['global_eff']\n",
    "    local_eff = scenario['local_eff']\n",
    "    \n",
    "    if route_f == 1:\n",
    "        plot_data = pd.DataFrame(dict(\n",
    "            theta = ['resilience (density)','resilience (largest_component)', 'directness', 'coverage','cohesion', 'global efficiency', 'local efficiency', 'length'],\n",
    "            r = [res_density/0.35, res_component/2042, directness, coverage/111, cohesion/1.84, global_eff, local_eff, length/350]\n",
    "        ))\n",
    "        fig = px.line_polar(plot_data, r='r', theta='theta', line_close=True, range_r = [0, 1.0])\n",
    "        fig.write_image(f'output\\images\\{prune_f:2f}_{route_f:2f}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2aa4ef88a60d511689f4f8de835e153dc4058a6f3d8ffa213cd6f60262bac7e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ox')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
